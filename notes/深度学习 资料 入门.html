<html>
<head>
  <title>深度学习 资料 入门</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/600240 (zh-CN, DDL); Windows/10.0.0 (Win64);"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="539"/>
<h1>深度学习 资料 入门</h1>

<div>
<span><div><div><div>视频课程：</div><ul><li><div><a href="https://www.deeplearning.ai/">deeplearning.ai</a></div></li><ul><li><div><a href="https://mooc.study.163.com/smartSpec/detail/1001319001.htm/?utm_source=weibo.com&amp;utm_medium=timeline&amp;utm_campaign=deepLearning&amp;utm_content=wnd20170831">网易云课堂</a></div></li><li><div><a href="https://www.coursera.org/specializations/deep-learning">coursera</a></div></li></ul><li><div><a href="https://web.stanford.edu/class/cs230/">CS230: Deep Learning</a></div></li><li><div><a href="http://cs231n.stanford.edu/">CS231n: Convolutional Neural Networks for Visual Recognition</a>：斯坦福CS231n李飞飞计算机视觉</div></li><ul><li><div><a href="https://study.163.com/course/introduction/1003223001.htm">网易云课堂</a>：2016</div></li><li><div><a href="https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC">youtube2016</a></div></li><li><div><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv">youtube2017</a></div></li></ul><li><div>吴恩达机器学习</div></li><ul><li><div><a href="https://study.163.com/course/introduction/1004570029.htm">网易云课堂</a></div></li><li><div><a href="https://www.coursera.org/learn/machine-learning">coursera</a></div></li></ul></ul><div>书：</div><ul><li><div><a href="https://book.douban.com/subject/27087503/">Deep Learning 深度学习</a></div></li><ul><li><div><a href="https://github.com/exacity/deeplearningbook-chinese">Deep Learning 中文翻译</a></div></li></ul></ul><div><a href="http://cs231n.stanford.edu/">CS231n</a>：</div><ul><li><div><a href="http://cs231n.stanford.edu/syllabus.html">课程安排</a></div></li><li><div>视频：</div></li><ul><li><div><a href="https://study.163.com/course/introduction/1003223001.htm">网易云课堂</a>：2016</div></li><li><div><a href="https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC">youtube2016</a></div></li><li><div><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv">youtube2017</a></div></li></ul><li><div><a href="http://cs231n.github.io/">Course Notes</a>：笔记、作业</div></li><ul><li><div><a href="https://web.hypothes.is/">hypothes.is</a>：一个给网页创建公开批注的chrome插件</div></li><li><div><a href="https://github.com/MahanFathi/CS231">MahanFathi/CS231</a>：MahanFathi的作业答案</div></li><li><div><a href="https://github.com/monkeyCv/cs231n_2018spring_assignment_solution">monkeyCv/cs231n_2018spring_assignment_solution</a>：monkeyCv的2018年作业答案</div></li><li><div><a href="https://zhuanlan.zhihu.com/p/21930884">CS231n官方笔记授权翻译</a></div></li></ul></ul><div><a href="http://cs231n.stanford.edu/">CS231n</a>：<a href="http://cs231n.github.io/">note</a> / <a href="https://zhuanlan.zhihu.com/p/21930884">笔记</a></div><ul><li><div>Lecture 1: Introduction and Historical Context</div></li><li><div>Lecture 2: Data-driven approach, kNN, Linear Classification 1（数据驱动的图像分类方式：K最近邻与线性分类器）</div></li><ul><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/classification/">Image Classification: Data-driven Approach, k-Nearest Neighbor, train/val/test splits</a></div></li><ul><li><div style="text-align: justify;"><a href="https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit">CS231n课程笔记翻译：图像分类笔记（上）</a></div></li><li><div><a href="https://zhuanlan.zhihu.com/p/20900216?refer=intelligentunit">CS231n课程笔记翻译：图像分类笔记（下）</a></div></li></ul></ul><li><div>总结：</div></li><ul><li><div><a href="https://baike.baidu.com/item/%E8%B6%85%E5%8F%82%E6%95%B0">超参数</a>，通过交叉验证来确定</div></li><li><div>参数化、非参数化：</div></li><ul><li><div><a href="https://www.cnblogs.com/dengdan890730/p/5636387.html">参数化方法与非参数化方法</a></div></li><li><div><a href="http://shujuren.org/article/106.html">参数和非参数机器学习算法</a></div></li></ul></ul></ul><li><div>Lecture 3: Linear Classification 2, Optimization</div></li><ul><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/linear-classify/">Linear classification: Support Vector Machine, Softmax</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit">CS231n课程笔记翻译：线性分类笔记（上）</a></div></li><li><div><a href="https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit">CS231n课程笔记翻译：线性分类笔记（中）</a></div></li><li><div><a href="https://zhuanlan.zhihu.com/p/21102293?refer=intelligentunit">CS231n课程笔记翻译：线性分类笔记（下）</a></div></li></ul><li><div><a href="http://cs231n.github.io/optimization-1/">Optimization: Stochastic Gradient Descent</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21360434?refer=intelligentunit">CS231n课程笔记翻译：最优化笔记（上）</a></div></li><li><div><a href="https://zhuanlan.zhihu.com/p/21387326?refer=intelligentunit">CS231n课程笔记翻译：最优化笔记（下）</a></div></li></ul></ul><li><div>互动：<a href="http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/">Linear Classification Loss Visualization</a></div></li><li><div>总结：</div></li><ul><li><div>正则化（regularization ）参数通过交叉验证来获取</div></li><li><div>SVM的损失函数是凸函数</div></li><li><div>梯度计算分数值梯度法和分析梯度法</div></li><li><div><a href="https://hit-scir.gitbooks.io/neural-networks-and-deep-learning-zh_cn/content/chap3/c3s4.html">Softmax</a>：同时用在后面的神经网络上</div></li></ul></ul><li><div>Lecture 4: Backpropagation, Neural Networks 1</div></li><ul><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/optimization-2/">Backpropagation, Intuitions</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit">CS231n课程笔记翻译：反向传播笔记</a></div></li></ul><li><div><a href="http://cs231n.github.io/neural-networks-1/">Neural Networks Part 1: Setting up the Architecture</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit">CS231n课程笔记翻译：神经网络笔记1（上）</a></div></li><li><div><a href="https://zhuanlan.zhihu.com/p/21513367?refer=intelligentunit">CS231n课程笔记翻译：神经网络笔记1（下）</a></div></li></ul></ul><li><div>互动：<a href="https://cs.stanford.edu/people/karpathy/convnetjs/index.html">ConvNetJS</a></div></li><ul><li><div><a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html">Interactively classify toy 2-D data with a Neural Network</a></div></li></ul><li><div>总结</div></li><ul><li><div>神经元越多越好，通过适当的正则化（regularization ）防止过拟合</div></li></ul></ul><li><div>Lecture 5: Neural Networks Part 2</div></li><ul><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/neural-networks-2/">Neural Networks Part 2: Setting up the Data and the Loss</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit">CS231n课程笔记翻译：神经网络笔记 2</a></div></li></ul></ul><li><div>总结：</div></li><ul><li><div><a href="https://www.cnblogs.com/makefile/p/activation-function.html">激活函数(ReLU, Swish, Maxout)</a>，用<span style="font-weight: bold;">ReLU</span>, 可尝试Leaky ReLU/ Maxout/ ELU, tanh效果不好，不要使用sigmoid。没有激活函数的神经网络等效于一个线性分类器</div></li><li><div>先用小数据集（几个几十个）测试网络能否overfit（全部分类对），检查实现是否正确，调整学习速率</div></li><li><div>通过网格遍历测试超参数的效果不如随机选取超参数测试好</div></li><li><div><img src="深度学习 资料 入门_files/Image.png" type="image/png" data-filename="Image.png" width="709"/></div></li></ul></ul><li><div>Lecture 6: Neural Networks Part 3 / Intro to ConvNets</div></li><ul><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/neural-networks-3/">Neural Networks Part 3: Learning and Evaluation</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit">CS231n课程笔记翻译：神经网络笔记3（上）</a></div></li><li><div><a href="https://zhuanlan.zhihu.com/p/21798784?refer=intelligentunit">CS231n课程笔记翻译：神经网络笔记3（下）</a></div></li></ul><li><div><a href="http://cs231n.github.io/neural-networks-case-study/">Putting it together: Minimal Neural Network Case Study</a></div></li></ul><li><div>总结：</div></li><ul><li><div>优化方法：</div></li><ul><li><div>一阶（只考虑梯度）：SGD, SGD+Momentum, Adagrad, RMSProp, <span style="font-weight: bold;">Adam</span>。均有超参数learning rate，最好使learning rate虽时间衰减</div></li><li><div>二阶（还考虑曲面弯曲程度，可以更快到达极小值）：硬算Hessian矩阵O(n^3)不可能，有BGFS O(n^2)和<span style="font-weight: bold;">L-BFGS</span>近似计算。没有超参数learning rate</div></li></ul><li><div>dropout：模型集成的思想，或认为可以获得更多特征。总可以提升性能</div></li></ul></ul><li><div>Lecture 7: Convolutional Neural Networks</div></li><ul><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/convolutional-networks/">Convolutional Neural Networks: Architectures, Convolution / Pooling Layers</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit">CS231n课程笔记翻译：卷积神经网络笔记</a></div></li></ul></ul><li><div>总结：</div></li><ul><li><div>卷积有很方便的后向传播梯度</div></li><li><div>通常使用<span style="font-weight: bold;">ReLU</span>做激活函数，在所有卷积层后</div></li></ul></ul><li><div>Lecture 8: Localization and Detection</div></li><ul><li><div>计算机视觉任务：分类（Classification）、分类+定位（Classification + Localization）、目标检测（Object Detection）、分割（Instance Segmentation）</div></li><li><div>Classification + Localization：</div></li><ul><li><div>固定目标数量为1</div></li><li><div>目标框（bbox）的检测可以看作回归问题。替换CNN的全连接层，输出层设置为目标框参数。两种方式：输出层大小</div></li><ul><li><div>不定类回归（class-agnostic regresar）：4</div></li><li><div>特定类回归（class-specific regresar）：C * 4</div></li></ul><li><div>也可定位固定数量的目标，应用：人体姿态估计</div></li><li><div>回归过程中最好反向传播整个CNN，而不是只训练全连接层。可以用两个网络分别实现分类和定位，而不是共享相同的CNN。</div></li><li><div>除了通过回归，还可以通过滑动窗口，在CNN中可以简化（Overfeat）</div></li></ul></ul><ul><li><div>Object Detection：</div></li><ul><li><div>不固定目标数量，不能完全当作回归，因为数量不固定，而是看作分类，利用滑窗</div></li><li><div>数据集：PASCAL VOC, ImageNet Detection, MS-COCO</div></li><li><div>R-CNN：</div></li><ul><li><div>为了减少计算量，先进行Region Proposals，提取可能存在目标对象的区域（如Selective Search）。然后通过CNN分类，Classification + Localization实现对目标框的微调</div></li><li><div>bbox regression：Region Proposals不够完美，通过卷积层输出的特征回归出bbox的修正量</div></li><li><div>由于R-CNN需要存储卷积层输出的所有特征再对全连接层进行训练，所以速度慢、占用空间多</div></li></ul><li><div>Fast R-CNN：</div></li><ul><li><div>通过CNN减少滑窗计算量。</div></li><li><div>解决全连接层输入大小的问题：Region of Interest Pooling</div></li><li><div>解决Fast R-CNN Region Proposals的问题：在卷积层输出特征后用CNN实现Region Proposals（Region Proposal Network）</div></li></ul><li><div>YOLO（You Only Look Once）：</div></li><ul><li><div>将检测问题看作回归问题</div></li></ul><li><div><img src="深度学习 资料 入门_files/Image [1].png" type="image/png" data-filename="Image.png"/></div></li></ul></ul><li><div>Lecture 9: Visualization, Deep Dream, Neural Style, Adversarial Examples</div></li><ul><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/understanding-cnn/">Understanding and Visualizing Convolutional Neural Networks</a></div></li></ul></ul></ul><div><a href="http://cs231n.stanford.edu/">CS231n</a>：<a href="http://cs231n.github.io/">assignment</a> / <a href="https://zhuanlan.zhihu.com/p/21930884">作业2016</a></div></div><ul><li><div>Assignment #1: Image Classification, kNN, SVM, Softmax, Neural Network (<a href="http://cs231n.github.io/assignments2018/assignment1/">2018</a> / <a href="http://cs231n.github.io/assignments2016/assignment1/">2016</a>)</div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21441838?refer=intelligentunit">斯坦福CS231n课程作业# 1简介</a></div></li><li><div><a href="https://github.com/MahanFathi/CS231/tree/master/assignment1">MahanFathi/CS231</a></div></li><li><div>总结：</div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/20878530">CS231n课程笔记翻译：Python Numpy教程</a>：如果运行这段代码出现类似ImportError: cannot import name imread的报错，那么请利用pip进行Pillow的下载，可以解决问题。命令：pip install Pillow。</div></li><li><div><a href="https://www.douban.com/group/topic/113236201/">史上最全的Python包管理工具：Anaconda教程</a>：在 Windows 上用 activate my_env 进入环境</div></li><li><div>点乘相加转换为矩阵乘法</div></li><li><div>在检验训练算法时可以先用少量样本，看能否成功过拟合</div></li></ul></ul><li><div>Assignment #2: Fully-Connected Nets, Batch Normalization, Dropout, Convolutional Nets (<a href="http://cs231n.github.io/assignments2018/assignment2/">2018</a> / <a href="http://cs231n.github.io/assignments2016/assignment2/">2016</a>)</div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21941485?refer=intelligentunit">斯坦福CS231n课程作业# 2简介</a></div></li><li><div><a href="https://github.com/MahanFathi/CS231/tree/master/assignment2">MahanFathi/CS231</a></div></li><li><div>总结：</div></li><ul><li><div><a href="https://study.163.com/course/courseLearn.htm?courseId=1003223001&amp;from=study#/learn/text?lessonId=1051303712&amp;courseId=1003223001">Assignment 2 Q1-Q3一段关于神经网络的故事</a>：</div></li><ul><li><div>如何通过链式法则求解矩阵表达式的局部梯度？矩阵维度适配（<a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit">CS231n课程笔记翻译：卷积神经网络笔记</a> P23）</div></li><li><div>批量归一化详解（<a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit">CS231n课程笔记翻译：卷积神经网络笔记</a> P32），note中没有，assignment中只给了文献：<a href="深度学习 资料 入门_files/1502.03167.pdf"><img src="深度学习 资料 入门_files/a4f2d1fc41ecb946d14fbae4f03153d3.png" alt="1502.03167.pdf"></a></div></li></ul><li><div>（2018新增）批量归一化（Batch Normalization）的效果受batch大小的影响，层归一化（Layer Normalization）解决了此问题：</div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/38755603">Batch-normalization与Layer-normalization</a>：区别</div></li><li><div><a href="https://blog.csdn.net/xwd18280820053/article/details/70237664">Batch Normalization &amp; Layer Normalization整理</a>：论文简介</div></li><li><div><a href="深度学习 资料 入门_files/1607.06450.pdf"><img src="深度学习 资料 入门_files/2232226bcaf95abbec86ee1b64be3357.png" alt="1607.06450.pdf"></a></div></li></ul><li><div><span style="font-weight: bold;">卷积层反向求导推导</span>（<a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit">CS231n课程笔记翻译：卷积神经网络笔记</a> P8），注意cs231n与高数教材对偏导的不同表示方法</div></li><ul><li><div><a href="https://blog.csdn.net/haolexiao/article/details/72628083">CNN中的梯度的求法和反向传播过程</a>：主要简述卷积层和卷积层求导</div></li><li><div><a href="https://www.cnblogs.com/pinard/p/6494810.html">卷积神经网络(CNN)反向传播算法</a></div></li></ul><li><div>TensorFlow：</div></li><ul><li><div><a href="https://www.tensorflow.org/tutorials/">官方教程</a></div></li><ul><li><div><a href="https://www.tensorflow.org/install/install_windows">安装</a></div></li></ul><li><div><a href="https://gpuopen.com/rocm-tensorflow-1-8-release/">AMD GPU安装</a>：仅支持linux</div></li></ul></ul><li><div>AMD GPU深度学习支持：<a href="https://blog.csdn.net/JackyTintin/article/details/74637157">AMD ROCm 平台简介</a></div></li></ul><li><div>Assignment #3: Image Captioning with Vanilla RNNs, Image Captioning with LSTMs, Network Visualization, Style Transfer, Generative Adversarial Networks（<a href="http://cs231n.github.io/assignments2018/assignment3/">2018</a> / <a href="http://cs231n.github.io/assignments2016/assignment3/">2016</a>）</div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21946525?refer=intelligentunit">斯坦福CS231n课程作业# 3简介</a></div></li></ul></ul><div><br/></div></div><div><br/></div></span>
</div></body></html> 