<html>
<head>
  <title>深度学习 资料 入门</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/600363 (zh-CN, DDL); Windows/10.0.0 (Win64);"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="539"/>
<h1>深度学习 资料 入门</h1>

<div>
<span><div><div><div>视频课程：</div><ul><li><div><a href="https://www.deeplearning.ai/">deeplearning.ai</a></div></li><ul><li><div><a href="https://mooc.study.163.com/smartSpec/detail/1001319001.htm/?utm_source=weibo.com&amp;utm_medium=timeline&amp;utm_campaign=deepLearning&amp;utm_content=wnd20170831">网易云课堂</a></div></li><li><div><a href="https://www.coursera.org/specializations/deep-learning">coursera</a></div></li></ul><li><div><a href="https://web.stanford.edu/class/cs230/">CS230: Deep Learning</a></div></li><li><div><a href="http://cs231n.stanford.edu/">CS231n: Convolutional Neural Networks for Visual Recognition</a>：斯坦福CS231n李飞飞计算机视觉</div></li><ul><li><div><a href="https://study.163.com/course/introduction/1003223001.htm">网易云课堂</a>：2016</div></li><li><div><a href="https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC">youtube2016</a></div></li><li><div><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv">youtube2017</a></div></li></ul><li><div>吴恩达机器学习</div></li><ul><li><div><a href="https://study.163.com/course/introduction/1004570029.htm">网易云课堂</a></div></li><li><div><a href="https://www.coursera.org/learn/machine-learning">coursera</a></div></li></ul></ul><div>书：</div><ul><li><div><a href="https://book.douban.com/subject/27087503/">Deep Learning 深度学习</a></div></li><ul><li><div><a href="https://github.com/exacity/deeplearningbook-chinese">Deep Learning 中文翻译</a></div></li></ul></ul><div><a href="http://cs231n.stanford.edu/">CS231n</a>：</div><ul><li><div><a href="http://cs231n.stanford.edu/syllabus.html">课程安排</a></div></li><li><div>视频：</div></li><ul><li><div><a href="https://study.163.com/course/introduction/1003223001.htm">网易云课堂</a>：2016</div></li><li><div><a href="https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC">youtube2016</a></div></li><li><div><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv">youtube2017</a></div></li></ul><li><div><a href="http://cs231n.github.io/">Course Notes</a>：笔记、作业</div></li><ul><li><div><a href="https://web.hypothes.is/">hypothes.is</a>：一个给网页创建公开批注的chrome插件</div></li><li><div><a href="https://github.com/MahanFathi/CS231">MahanFathi/CS231</a>：MahanFathi的作业答案</div></li><li><div><a href="https://github.com/monkeyCv/cs231n_2018spring_assignment_solution">monkeyCv/cs231n_2018spring_assignment_solution</a>：monkeyCv的2018年作业答案</div></li><li><div><a href="https://zhuanlan.zhihu.com/p/21930884">CS231n官方笔记授权翻译</a></div></li></ul></ul><div><a href="http://cs231n.stanford.edu/">CS231n</a>：<a href="http://cs231n.github.io/">note</a> / <a href="https://zhuanlan.zhihu.com/p/21930884">笔记</a></div><ul><li><div>Lecture 1: Introduction and Historical Context</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture1_Intro to Computer Vision, historical context.pdf"><img src="深度学习 资料 入门_files/cbed4a563e92df091391f5458a0a1bcc.png" alt="winter1516_lecture1_Intro to Computer Vision, historical context.pdf"></a></div></li></ul><li><div>Lecture 2: Data-driven approach, kNN, Linear Classification 1（数据驱动的图像分类方式：K最近邻与线性分类器）</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture2_KNN.pdf"><img src="深度学习 资料 入门_files/3654299eddcd1b62f7fa6ca28cc6f25f.png" alt="winter1516_lecture2_KNN.pdf"></a></div></li><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/classification/">Image Classification: Data-driven Approach, k-Nearest Neighbor, train/val/test splits</a></div></li><ul><li><div style="text-align: justify;"><a href="https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit">CS231n课程笔记翻译：图像分类笔记（上）</a></div></li><li><div><a href="https://zhuanlan.zhihu.com/p/20900216?refer=intelligentunit">CS231n课程笔记翻译：图像分类笔记（下）</a></div></li></ul></ul><li><div>总结：</div></li><ul><li><div><a href="https://baike.baidu.com/item/%E8%B6%85%E5%8F%82%E6%95%B0">超参数</a>，通过交叉验证来确定</div></li><li><div>参数化、非参数化：</div></li><ul><li><div><a href="https://www.cnblogs.com/dengdan890730/p/5636387.html">参数化方法与非参数化方法</a></div></li><li><div><a href="http://shujuren.org/article/106.html">参数和非参数机器学习算法</a></div></li></ul></ul></ul><li><div>Lecture 3: Linear Classification 2, Optimization</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture3_loss_function_and_optimization.pdf"><img src="深度学习 资料 入门_files/b4e8d8e3a7c2398a9d37727298c8408d.png" alt="winter1516_lecture3_loss_function_and_optimization.pdf"></a></div></li><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/linear-classify/">Linear classification: Support Vector Machine, Softmax</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit">CS231n课程笔记翻译：线性分类笔记（上）</a></div></li><li><div><a href="https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit">CS231n课程笔记翻译：线性分类笔记（中）</a></div></li><li><div><a href="https://zhuanlan.zhihu.com/p/21102293?refer=intelligentunit">CS231n课程笔记翻译：线性分类笔记（下）</a></div></li></ul><li><div><a href="http://cs231n.github.io/optimization-1/">Optimization: Stochastic Gradient Descent</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21360434?refer=intelligentunit">CS231n课程笔记翻译：最优化笔记（上）</a></div></li><li><div><a href="https://zhuanlan.zhihu.com/p/21387326?refer=intelligentunit">CS231n课程笔记翻译：最优化笔记（下）</a></div></li></ul></ul><li><div>互动：<a href="http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/">Linear Classification Loss Visualization</a></div></li><li><div>总结：</div></li><ul><li><div>正则化（regularization ）参数通过交叉验证来获取</div></li><li><div>SVM的损失函数是凸函数</div></li><li><div>梯度计算分数值梯度法和分析梯度法</div></li><li><div><a href="https://hit-scir.gitbooks.io/neural-networks-and-deep-learning-zh_cn/content/chap3/c3s4.html">Softmax</a>：同时用在后面的神经网络上</div></li></ul></ul><li><div>Lecture 4: Backpropagation, Neural Networks 1</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture4_backpropagation.pdf"><img src="深度学习 资料 入门_files/20f33c5ecd5927a2156d69fc97e6104f.png" alt="winter1516_lecture4_backpropagation.pdf"></a></div></li><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/optimization-2/">Backpropagation, Intuitions</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit">CS231n课程笔记翻译：反向传播笔记</a></div></li></ul><li><div><a href="http://cs231n.github.io/neural-networks-1/">Neural Networks Part 1: Setting up the Architecture</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit">CS231n课程笔记翻译：神经网络笔记1（上）</a></div></li><li><div><a href="https://zhuanlan.zhihu.com/p/21513367?refer=intelligentunit">CS231n课程笔记翻译：神经网络笔记1（下）</a></div></li></ul></ul><li><div>互动：<a href="https://cs.stanford.edu/people/karpathy/convnetjs/index.html">ConvNetJS</a></div></li><ul><li><div><a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html">Interactively classify toy 2-D data with a Neural Network</a></div></li></ul><li><div>总结</div></li><ul><li><div>神经元越多越好，通过适当的正则化（regularization ）防止过拟合</div></li></ul></ul><li><div>Lecture 5: Neural Networks Part 2</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture5_training_neural_network_part1.pdf"><img src="深度学习 资料 入门_files/3b71a22abbd0555390c12ea773bfd4f4.png" alt="winter1516_lecture5_training_neural_network_part1.pdf"></a></div></li><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/neural-networks-2/">Neural Networks Part 2: Setting up the Data and the Loss</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit">CS231n课程笔记翻译：神经网络笔记 2</a></div></li></ul></ul><li><div>总结：</div></li><ul><li><div><a href="https://www.cnblogs.com/makefile/p/activation-function.html">激活函数(ReLU, Swish, Maxout)</a>，用<span style="font-weight: bold;">ReLU</span>, 可尝试Leaky ReLU/ Maxout/ ELU, tanh效果不好，不要使用sigmoid。没有激活函数的神经网络等效于一个线性分类器</div></li><li><div>先用小数据集（几个几十个）测试网络能否overfit（全部分类对），检查实现是否正确，调整学习速率</div></li><li><div>通过网格遍历测试超参数的效果不如随机选取超参数测试好</div></li><li><div><img src="深度学习 资料 入门_files/Image.png" type="image/png" data-filename="Image.png" width="709"/></div></li></ul></ul><li><div>Lecture 6: Neural Networks Part 3 / Intro to ConvNets</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture6_training_neural_network_part2.pdf"><img src="深度学习 资料 入门_files/d21ac62c3c3bcc9e1c4eed272105725f.png" alt="winter1516_lecture6_training_neural_network_part2.pdf"></a></div></li><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/neural-networks-3/">Neural Networks Part 3: Learning and Evaluation</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit">CS231n课程笔记翻译：神经网络笔记3（上）</a></div></li><li><div><a href="https://zhuanlan.zhihu.com/p/21798784?refer=intelligentunit">CS231n课程笔记翻译：神经网络笔记3（下）</a></div></li></ul><li><div><a href="http://cs231n.github.io/neural-networks-case-study/">Putting it together: Minimal Neural Network Case Study</a></div></li></ul><li><div>总结：</div></li><ul><li><div>优化方法：</div></li><ul><li><div>一阶（只考虑梯度）：SGD, SGD+Momentum, Adagrad, RMSProp, <span style="font-weight: bold;">Adam</span>。均有超参数learning rate，最好使learning rate虽时间衰减</div></li><li><div>二阶（还考虑曲面弯曲程度，可以更快到达极小值）：硬算Hessian矩阵O(n^3)不可能，有BGFS O(n^2)和<span style="font-weight: bold;">L-BFGS</span>近似计算。没有超参数learning rate</div></li></ul><li><div>dropout：模型集成的思想，或认为可以获得更多特征。总可以提升性能</div></li></ul></ul><li><div>Lecture 7: Convolutional Neural Networks</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture7_convolutional_neural_network.pdf"><img src="深度学习 资料 入门_files/d3f72c7f77ecf3cada40667ff3e0613e.png" alt="winter1516_lecture7_convolutional_neural_network.pdf"></a></div></li><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/convolutional-networks/">Convolutional Neural Networks: Architectures, Convolution / Pooling Layers</a></div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit">CS231n课程笔记翻译：卷积神经网络笔记</a></div></li></ul></ul><li><div>总结：</div></li><ul><li><div>卷积有很方便的后向传播梯度</div></li><li><div>通常使用<span style="font-weight: bold;">ReLU</span>做激活函数，在所有卷积层后</div></li></ul></ul><li><div>Lecture 8: Localization and Detection</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture8_location_and_detection.pdf"><img src="深度学习 资料 入门_files/5c5d2aa6911c85e5c05767713d5c4284.png" alt="winter1516_lecture8_location_and_detection.pdf"></a></div></li><li><div>计算机视觉任务：分类（Classification）、分类+定位（Classification + Localization）、目标检测（Object Detection）、分割（Instance Segmentation）</div></li><li><div>Classification + Localization：</div></li><ul><li><div>固定目标数量为1</div></li><li><div>目标框（bbox）的检测可以看作回归问题。替换CNN的全连接层，输出层设置为目标框参数。两种方式：输出层大小</div></li><ul><li><div>不定类回归（class-agnostic regresar）：4</div></li><li><div>特定类回归（class-specific regresar）：C * 4</div></li></ul><li><div>也可定位固定数量的目标，应用：人体姿态估计</div></li><li><div>回归过程中最好反向传播整个CNN，而不是只训练全连接层。可以用两个网络分别实现分类和定位，而不是共享相同的CNN。</div></li><li><div>除了通过回归，还可以通过滑动窗口，在CNN中可以简化（Overfeat）</div></li></ul><li><div>Object Detection：</div></li><ul><li><div>不固定目标数量，不能完全当作回归，因为数量不固定，而是看作分类，利用滑窗</div></li><li><div>数据集：PASCAL VOC, ImageNet Detection, MS-COCO</div></li><li><div>R-CNN（Region-based CNN）：</div></li><ul><li><div>为了减少计算量，先进行Region Proposals，提取可能存在目标对象的区域（如Selective Search）。然后通过CNN分类，Classification + Localization实现对目标框的微调</div></li><li><div>bbox regression：Region Proposals不够完美，通过卷积层输出的特征回归出bbox的修正量</div></li><li><div>由于R-CNN需要存储卷积层输出的所有特征再对全连接层进行训练，所以速度慢、占用空间多</div></li></ul><li><div>Fast R-CNN：</div></li><ul><li><div>通过CNN减少滑窗计算量。</div></li><li><div>解决全连接层输入大小的问题：Region of Interest Pooling</div></li><li><div>解决Fast R-CNN Region Proposals的问题：在卷积层输出特征后用CNN实现Region Proposals（Region Proposal Network）</div></li></ul><li><div>YOLO（You Only Look Once）：</div></li><ul><li><div>将检测问题看作回归问题</div></li></ul><li><div><img src="深度学习 资料 入门_files/Image [1].png" type="image/png" data-filename="Image.png"/></div></li></ul></ul><li><div>Lecture 9: Visualization, Deep Dream, Neural Style, Adversarial Examples</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture9_understanding_and_visualizaing_neural_network.pdf"><img src="深度学习 资料 入门_files/285e3eef638b24aaed425bd124bc3c63.png" alt="winter1516_lecture9_understanding_and_visualizaing_neural_network.pdf"></a></div></li><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/understanding-cnn/">Understanding and Visualizing Convolutional Neural Networks</a></div></li></ul><li><div>总结：</div></li><ul><li><div>t-SNE：可视化工具，高维数据聚类为二维</div></li><li><div>Deep Visualization Toolbox：实时可视化深度神经网络的运行状态：</div></li><ul><li><div>Deconv：可视化某神经元对输入图像的响应，修改了relu层反向传播梯度的方法，只传播正影响</div></li><li><div>Optimization to Image：固定神经网络参数，初始化输入图像为0，对图像像素进行优化，优化目标最大化某类的分数；可视化对目标区域的响应，可以用于分割</div></li></ul><li><div>通过卷积层输出的特征向量重建原图像：对图像像素进行优化，优化目标最小化特征向量之间的距离</div></li><li><div>DeepDream：输入图像向前传播到某层，使各神经元梯度等于其激活，再反向传播改变图像。放大了使网络激活的特征。dream的深度影响了放大的特征的抽象程度</div></li><li><div>NeuralStyle：将原图像和风格图像传入神经网络，图像内容与各层的激活相关，图像风格与各层激活的外积相关。优化目标最小化与原图的内容距离和与风格图像的风格距离。内容常只用某层的激活，风格用很多层。（此情况可用二阶优化算法，如LBFGS，数据量小）</div></li><li><div>可通过优化生成对抗样本</div></li></ul></ul><li><div>Lecture 10: Recurrent Neural Networks, Image Captioning, LSTM</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture10_recurrent_neural_network.pdf"><img src="深度学习 资料 入门_files/1f0fffd20c98a3e3f4ccb108faaa9732.png" alt="winter1516_lecture10_recurrent_neural_network.pdf"></a></div></li><li><div>总结：</div></li><ul><li><div>RNN用于文字序列生成，结合CNN用于图像标注，更复杂的注意力RNN标注图像</div></li><li><div>Vanilla RNN：The state consists of a single “hidden” vector h. Simple but don’t work very well</div></li><li><div>多层RNN</div></li><li><div>LSTM (Long Short Time Memory)：不同于普通RNN直接通过线性变换将旧隐藏状态转换为新隐藏状态，LSTM通过累加来改变隐藏状态，类似于ResNet，解决了梯度消隐或爆炸的问题。GRU简化了LSTM。</div></li></ul></ul><li><div>Lecture 11: ConvNets in practice</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture11_cnn_in_practice.pdf"><img src="深度学习 资料 入门_files/1eda6717c62e90013681dd8ca63bddde.png" alt="winter1516_lecture11_cnn_in_practice.pdf"></a></div></li><li><div>note：</div></li><ul><li><div><a href="http://cs231n.github.io/transfer-learning/">Transfer Learning and Fine-tuning Convolutional Neural Networks</a></div></li></ul><li><div>总结：</div></li><ul><li><div>数据增强（Data Augmentation）：通过缩放、旋转、剪切、颜色变换、Color jitter来尽可能利用数据集、避免过拟合，可以看作一种正则化方法（Dropout、Batch normalization、Model ensembles等都可以看作正则化方法)</div></li><li><div>迁移学习（Transfer Learning）：下载训练好的CNN，根据训练数据的大小，可以调节训练的深度。对于固定的层，可以将其运算结果存储在硬盘中，减少计算量。</div></li><ul><li><div>Caffe ConvNet library  has a “<a href="https://github.com/BVLC/caffe/wiki/Model-Zoo">Model Zoo</a>” of pretrained models: Caffe模型几乎成为标准，可以由不同的深度学习库导入</div></li></ul><li><div>卷积（Convolutions）：</div></li><ul><li><div>分解：</div></li><ul><li><div>多层的3*3卷积比单层的大窗口卷积参数更少、计算量更小、非线性更强；</div></li><li><div>Bottleneck sandwich比普通的3*3卷积参数更少、计算量更小、非线性更强。</div></li><li><div>3*3卷积还可以分解成1*3、3*1卷积</div></li><li><div>还有其他更复杂的分解使计算量更低，已经应用在GoodleNet中</div></li></ul><li><div>简便算法：</div></li><ul><li><div>通过将卷积转换为矩阵乘法</div></li><li><div>或将卷积转换为FFT，但FFT在小卷积窗中优势不明显，且不能控制步长</div></li><li><div>类似于矩阵乘法，卷积也有一些快速算法。</div></li></ul></ul><li><div>速度优化：</div></li><ul><li><div>GPU</div></li><li><div>将训练集转换为原始像素并存储为连续序列</div></li><li><div>用16位精度浮点，或定点数。乘法运算时用更高精度的表示，再转换为低精度，不通过四舍五入二十根据误差概率地转换为临近的值。甚至在向前传播时用1位</div></li></ul></ul></ul><li><div>Lecture 12: Deep Learning libraries</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture12_deep_learning_package.pdf"><img src="深度学习 资料 入门_files/36ff381b91e5217962f40bc44ab2fd24.png" alt="winter1516_lecture12_deep_learning_package.pdf"></a></div></li><li><div>Caffe：</div></li><ul><li><div>特点：C++编写，Python、Matlab可调用。</div></li><li><div>优缺点：</div></li><ul><li><div>优点：</div></li><ul><li><div>对于标准前馈卷积神经网络非常方便</div></li><li><div>可以可以不用写代码就可以定义、训练Net</div></li></ul><li><div>缺点：</div></li><ul><li><div>一些文档过时，需要看代码</div></li><li><div>自定义层需要写C++/CUDA代码</div></li><li><div>不适合recurrent networks</div></li></ul></ul><li><div>步骤：</div></li><ul><li><div>转换数据：<span style="font-weight: bold;">LMDB</span>/HDF5</div></li><li><div>定义Net：写.prototxt文件，也有人用代码生成，可以下载训练好的网络和权重</div></li><li><div>（Protocol Buffer：用.prototxt来表示类，可以转换成各种语言，用来表示net和solver，不用写代码）</div></li><li><div>定义Solver：学习率、正则化参数等</div></li></ul><li><div>Python接口：</div></li><ul><li><div>没有多少文档（2016年），主要阅读以下代码</div></li><ul><li><div>caffe/python/caffe/_caffe.cpp</div></li><li><div>caffe/python/caffe/pycaffe.py</div></li></ul><li><div>可以用于定义Net（CPU）、自定义损失函数、提取特征</div></li></ul><li><div>结构：</div></li><ul><li><div>Blob：存储数据、参数等，n维张量，存储有CPU、GPU的数据和diffs</div></li><li><div>Layer：输入Blob（Bottom Blob），输出Blob（Top Blob）</div></li><li><div>Net：Layers的集合</div></li><li><div>Solver：用梯度来更新权重</div></li></ul><li><div>Net下载：Model Zoo</div></li></ul><li><div><span style="font-weight: bold;">Torch</span>：</div></li><ul><li><div>特点：</div></li><ul><li><div>C和lua编写</div></li><li><div>lua的循环很快</div></li></ul><li><div>优缺点：</div></li><ul><li><div>优点：有一定灵活性，很多预训练的模型，自己编写层时很方便地运行在GPU上，模块化设计容易组合</div></li><li><div>缺点：比Caffe更麻烦，不适用与RNNs</div></li></ul><li><div>步骤：转换数据（HDF5）、训练模型、使用模型</div></li><li><div>结构：</div></li><ul><li><div>Tensor：接口与numpy矩阵相同，转换为GPU类型后运算就在GPU进行，有文档</div></li><li><div>nn：神经网络</div></li><li><div>optim：自动向前后运行网络，得到loss和梯度，更新权重</div></li><li><div>modules：没有layer，updateOutput、updateGradInput、accGradParameters等，Container模块可以结合多个模块</div></li><li><div>nngraph：计算图，可以实现更复杂的设计，定义的符号变量</div></li></ul><li><div>Net下载：loadcaffe可以加载caffe的模型</div></li></ul><li><div>Theano：</div></li><ul><li><div>特点：</div></li><ul><li><div>使用python和numpy</div></li><li><div>计算图，先定义运算后输入参数（可通过numpy数组实例化），定义时自动进行优化</div></li><li><div>共享变量，解决GPU、CPU之间频繁交换数据的问题</div></li></ul><li><div>优缺点：</div></li><ul><li><div>优点：适用于RNN，有高层级的封装</div></li><li><div>缺点：API较复杂，预训练的模型相较不够好，原始的Theano偏向底层</div></li></ul><li><div>结构：</div></li><ul><li><div>Lasagne：High Level Wrapper</div></li><li><div>Keras：封装层级更高，也用tensorflow做后端。但用Theano作后端出bug后错误信息难看，Debug困难</div></li></ul><li><div>Net下载：Theano Model Zoo</div></li></ul><li><div>TensorFlow：</div></li><ul><li><div>特点：</div></li><ul><li><div>使用python和numpy</div></li><li><div>第一个由职业工程师编写</div></li><li><div>类似于Theano的符号运算-&gt;placeholder，共享变量-&gt;变量，先定义计算图，再通过numpy数组实例化，用session运算</div></li><li><div>Tensorboard：浏览器可视化，方便调试，误差、参数分布、模型结构</div></li><li><div>多GPU并行运算、分割网络并行运算</div></li></ul><li><div>优缺点：</div></li><ul><li><div>优点：计算图，比Theano编译更快、更方便，并行运算、分布式运算</div></li><li><div>缺点：预训练的模型较少，更复杂</div></li></ul></ul><li><div>比较：</div></li><ul><li><div><img src="深度学习 资料 入门_files/Image [2].png" type="image/png" data-filename="Image.png" width="694"/></div></li></ul><li><div>用例：PPT </div></li><ul><li><div><img src="深度学习 资料 入门_files/Image [3].png" type="image/png" data-filename="Image.png"/></div></li></ul></ul><li><div>Lecture 13: Segmentation, soft attention, spatial transformers</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture13_segmentation_and_attention.pdf"><img src="深度学习 资料 入门_files/2c3207d1212533b9f8b2818d6b9fd25c.png" alt="winter1516_lecture13_segmentation_and_attention.pdf"></a></div></li><li><div>语义分割（Semantic Segmentation）：</div></li><ul><li><div>不区分目标个体</div></li><li><div>分块进CNN做分类/直接向CNN输入高分辨率图像</div></li><li><div>图像金字塔，多尺度；结合超像素</div></li><li><div>反卷积（Deconvolution / convolution transpose）：由于CNN输出低分辨率分割，添加自学习上采样</div></li><li><div>数据集：Pascal语义分割数据集</div></li></ul><li><div>实例分割（Instance Segmentation）：</div></li><ul><li><div>得到每个分类的实例，类似于object detection的流程</div></li><li><div>类似于R-CNN（Region-based CNN），先进行Region Proposals</div></li><li><div>级联（Casades）</div></li></ul><li><div>注意力模型（Attention Models：）</div></li><ul><li><div>图像标注</div></li><li><div>Soft vs Hard Attentions：</div></li><ul><li><div>Soft概率分布全局加权</div></li><li><div>Hard取出子集，但不能进行梯度传播，应采用强化学习（Reinforcement learning，暂不涉及）</div></li></ul><li><div>翻译：对于可变长概率分布，需要特殊处理</div></li><li><div>视频标注（Video Captioning）：帧序列概率分布</div></li><li><div>空间转换（Spartial Transformer）：可以梯度传播地截取任意大小区域，自动进行旋转、仿射等变换</div></li></ul></ul><li><div>Lecture 14: Videos and Unsupervised Learning</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture14.pdf"><img src="深度学习 资料 入门_files/6b6cf864b3f316378c2f05e3c29fa061.png" alt="winter1516_lecture14.pdf"></a></div></li><li><div>视频：</div></li><ul><li><div>时空卷积网络（Spatio-Temporal ConvNets）：3D卷积，像素和时间上的卷积。目前还无法学习到如光流那样的特征，可能因为数据集不够，因此可以结合CNN和光流。局部动作</div></li><li><div>RNN：可以结合整个视频给出预测。全局动作</div></li><li><div>结合3D卷积CNN和RNN：有分开使用和合并使用（GRU-RCN）两种方法</div></li></ul><li><div>非监督学习：没有标签，在数据中寻找结构。</div></li><ul><li><div>自动编码器（Autoencoders）：</div></li><ul><li><div>Traditional：先conv后de-conv，与原图比较，取conv后输出即为特征（但效果不好）。在2000s用于Greedy Training（现在由于Relu、初始化方法、Batch Normalization的发明已经不用了）</div></li><li><div>Variantional：引入概率分布？从原数据集中生成样本</div></li></ul><li><div>生成对抗网络（Generative Adversarial Networks / GAN）</div></li><ul><li><div>从原数据集中生成样本，但不用考虑概率分布等数学原理</div></li><li><div>多尺度方法（Multiscale）</div></li><li><div>简化的方法：简单使用带批正则化的卷积神经网络</div></li><li><div>特征向量甚至能进行一些向量运算来生成符合逻辑的样本</div></li></ul></ul></ul><li><div>Lecture 15: Invited Talk by Jeff Dean</div></li><ul><li><div><a href="深度学习 资料 入门_files/winter1516_lecture15.pdf"><img src="深度学习 资料 入门_files/dc2100cb43136adeca51d7f54ee8291d.png" alt="winter1516_lecture15.pdf"></a></div></li><li><div>正则化技巧：soft targets</div></li></ul></ul><div><a href="http://cs231n.stanford.edu/">CS231n</a>：<a href="http://cs231n.github.io/">assignment</a> / <a href="https://zhuanlan.zhihu.com/p/21930884">作业2016</a></div></div><ul><li><div>Assignment #1: Image Classification, kNN, SVM, Softmax, Neural Network (<a href="http://cs231n.github.io/assignments2018/assignment1/">2018</a> / <a href="http://cs231n.github.io/assignments2016/assignment1/">2016</a>)</div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21441838?refer=intelligentunit">斯坦福CS231n课程作业# 1简介</a></div></li><li><div><a href="https://study.163.com/course/introduction/1003223001.htm">网易云课堂</a></div></li><li><div><a href="https://github.com/MahanFathi/CS231/tree/master/assignment1">MahanFathi/CS231</a></div></li><li><div>总结：</div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/20878530">CS231n课程笔记翻译：Python Numpy教程</a>：如果运行这段代码出现类似ImportError: cannot import name imread的报错，那么请利用pip进行Pillow的下载，可以解决问题。命令：pip install Pillow。</div></li><li><div><a href="https://www.douban.com/group/topic/113236201/">史上最全的Python包管理工具：Anaconda教程</a>：在 Windows 上用 activate my_env 进入环境</div></li><li><div>点乘相加转换为矩阵乘法</div></li><li><div>在检验训练算法时可以先用少量样本，看能否成功过拟合</div></li></ul></ul><li><div>Assignment #2: Fully-Connected Nets, Batch Normalization, Dropout, Convolutional Nets (<a href="http://cs231n.github.io/assignments2018/assignment2/">2018</a> / <a href="http://cs231n.github.io/assignments2016/assignment2/">2016</a>)</div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21941485?refer=intelligentunit">斯坦福CS231n课程作业# 2简介</a></div></li><li><div><a href="https://study.163.com/course/introduction/1003223001.htm">网易云课堂</a></div></li><li><div><a href="https://github.com/MahanFathi/CS231/tree/master/assignment2">MahanFathi/CS231</a></div></li><li><div>总结：</div></li><ul><li><div><a href="https://study.163.com/course/courseLearn.htm?courseId=1003223001&amp;from=study#/learn/text?lessonId=1051303712&amp;courseId=1003223001">Assignment 2 Q1-Q3一段关于神经网络的故事</a>：</div></li><ul><li><div>如何通过链式法则求解矩阵表达式的局部梯度？矩阵维度适配（<a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit">CS231n课程笔记翻译：卷积神经网络笔记</a> P23）</div></li><li><div>批量归一化详解（<a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit">CS231n课程笔记翻译：卷积神经网络笔记</a> P32），note中没有，assignment中只给了文献：<a href="深度学习 资料 入门_files/1502.03167.pdf"><img src="深度学习 资料 入门_files/a4f2d1fc41ecb946d14fbae4f03153d3.png" alt="1502.03167.pdf"></a></div></li></ul><li><div>（2018新增）批量归一化（Batch Normalization）的效果受batch大小的影响，层归一化（Layer Normalization）解决了此问题：</div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/38755603">Batch-normalization与Layer-normalization</a>：区别</div></li><li><div><a href="https://blog.csdn.net/xwd18280820053/article/details/70237664">Batch Normalization &amp; Layer Normalization整理</a>：论文简介</div></li><li><div><a href="深度学习 资料 入门_files/1607.06450.pdf"><img src="深度学习 资料 入门_files/2232226bcaf95abbec86ee1b64be3357.png" alt="1607.06450.pdf"></a></div></li></ul><li><div><span style="font-weight: bold;">卷积层反向求导推导</span>（<a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit">CS231n课程笔记翻译：卷积神经网络笔记</a> P8），注意cs231n与高数教材对偏导的不同表示方法</div></li><ul><li><div><a href="https://blog.csdn.net/haolexiao/article/details/72628083">CNN中的梯度的求法和反向传播过程</a>：主要简述卷积层和卷积层求导</div></li><li><div><a href="https://www.cnblogs.com/pinard/p/6494810.html">卷积神经网络(CNN)反向传播算法</a></div></li></ul><li><div>TensorFlow：</div></li><ul><li><div><a href="https://www.tensorflow.org/tutorials/">官方教程</a>  </div></li><ul><li><div><a href="https://www.tensorflow.org/install/install_windows">安装</a></div></li></ul><li><div><a href="https://gpuopen.com/rocm-tensorflow-1-8-release/">AMD GPU安装</a>：仅支持linux</div></li></ul></ul><li><div>AMD GPU深度学习支持：</div></li><ul><li><div><a href="https://blog.csdn.net/JackyTintin/article/details/74637157">AMD ROCm 平台简介</a></div></li><li><div><a href="https://rocm.github.io/dl.html">Deep Learning on ROCm</a></div></li></ul></ul><li><div>Assignment #3: Image Captioning with Vanilla RNNs, Image Captioning with LSTMs, Network Visualization, Style Transfer, Generative Adversarial Networks（<a href="http://cs231n.github.io/assignments2018/assignment3/">2018</a> / <a href="http://cs231n.github.io/assignments2016/assignment3/">2016</a>）</div></li><ul><li><div><a href="https://zhuanlan.zhihu.com/p/21946525?refer=intelligentunit">斯坦福CS231n课程作业# 3简介</a></div></li><li><div><a href="https://study.163.com/course/introduction/1003223001.htm">网易云课堂</a></div></li><li><div><a href="https://github.com/MahanFathi/CS231/tree/master/assignment3">MahanFathi/CS231</a></div></li><li><div>总结：</div></li><ul><li><div>Vanilla RNN：在图像标注中，隐藏状态通过CNN的输出的线性变换初始化，每次通过线性变换将隐藏层转换为每个单词（或字符）的得分，并将单词作为下一次的输入。由于隐藏状态经过矩阵的多次乘积，有梯度消隐或爆炸的问题</div></li><li><div>LSTM（Long-Short Term Memory）：梯度的传播有两条路径，详细推导参考<a href="https://study.163.com/course/introduction/1003223001.htm">网易云课堂</a></div></li><li><div>可视化：</div></li><ul><li><div>Saliency Maps: Saliency maps are a quick way to tell which part of the image influenced the classification decision made by the network.</div></li><li><div>Fooling Images: We can perturb an input image so that it appears the same to humans, but will be misclassified by the pretrained network.</div></li><li><div>Class Visualization: We can synthesize an image to maximize the classification score of a particular class; this can give us some sense of what the network is looking for when it classifies images of that class.</div></li><li><div><img src="深度学习 资料 入门_files/Image [4].png" type="image/png" data-filename="Image.png"/></div></li></ul><li><div>Style Transfer：可通过相邻像素差的L2范数来正则化</div></li><li><div>生成对抗网络（Generative Adversarial Networks / GANs）：</div></li><ul><li><div>更新生成器（G）来最小化判别器做出正确选择的概率</div></li><li><div>更新判别器（D）来最大化判别器做出正确选择的概率</div></li><li><div>为了避免判别器置信度高时生成器梯度消失的问题，将第一条改为：更新生成器（G）来最大化判别器在生成数据上做出错误选择的概率</div></li></ul></ul></ul></ul><div><br/></div></div><div><br/></div></span>
</div></body></html> 